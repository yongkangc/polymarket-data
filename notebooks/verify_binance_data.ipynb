{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binance Price Data Verification\n",
    "\n",
    "This notebook verifies the quality and completeness of the Binance minute-by-minute price data.\n",
    "\n",
    "**Data**: `data/binance_sep_dec28_2025_partial_minute_data.csv`\n",
    "\n",
    "**Coverage**: Sept 1 - Dec 5, 2025\n",
    "\n",
    "**Symbols**: BTCUSDT, ETHUSDT, SOLUSDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 77,625\n",
      "Memory usage: 8.29 MB\n",
      "\n",
      "Columns: ['symbol', 'timestamp', 'open', 'high', 'low', 'close', 'volume', 'trades']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>trades</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:00:00</td>\n",
       "      <td>108246.36</td>\n",
       "      <td>108260.00</td>\n",
       "      <td>108210.66</td>\n",
       "      <td>108260.00</td>\n",
       "      <td>15.88924</td>\n",
       "      <td>2717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:01:00</td>\n",
       "      <td>108260.00</td>\n",
       "      <td>108332.35</td>\n",
       "      <td>108259.99</td>\n",
       "      <td>108332.35</td>\n",
       "      <td>12.94030</td>\n",
       "      <td>1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:02:00</td>\n",
       "      <td>108332.35</td>\n",
       "      <td>108332.35</td>\n",
       "      <td>108256.43</td>\n",
       "      <td>108256.44</td>\n",
       "      <td>25.92896</td>\n",
       "      <td>2136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:03:00</td>\n",
       "      <td>108256.44</td>\n",
       "      <td>108282.43</td>\n",
       "      <td>108229.17</td>\n",
       "      <td>108229.18</td>\n",
       "      <td>18.99223</td>\n",
       "      <td>2344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:04:00</td>\n",
       "      <td>108229.18</td>\n",
       "      <td>108229.18</td>\n",
       "      <td>108100.00</td>\n",
       "      <td>108100.00</td>\n",
       "      <td>12.05048</td>\n",
       "      <td>3790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:05:00</td>\n",
       "      <td>108100.00</td>\n",
       "      <td>108110.46</td>\n",
       "      <td>108060.00</td>\n",
       "      <td>108070.04</td>\n",
       "      <td>45.33450</td>\n",
       "      <td>5961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:06:00</td>\n",
       "      <td>108070.04</td>\n",
       "      <td>108086.17</td>\n",
       "      <td>108015.00</td>\n",
       "      <td>108074.49</td>\n",
       "      <td>26.80768</td>\n",
       "      <td>4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:07:00</td>\n",
       "      <td>108074.50</td>\n",
       "      <td>108152.44</td>\n",
       "      <td>108043.23</td>\n",
       "      <td>108152.43</td>\n",
       "      <td>17.08691</td>\n",
       "      <td>3203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:08:00</td>\n",
       "      <td>108152.43</td>\n",
       "      <td>108152.43</td>\n",
       "      <td>108034.16</td>\n",
       "      <td>108037.77</td>\n",
       "      <td>75.56924</td>\n",
       "      <td>3241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BTCUSDT</td>\n",
       "      <td>2025-09-01 00:09:00</td>\n",
       "      <td>108037.77</td>\n",
       "      <td>108037.78</td>\n",
       "      <td>107983.00</td>\n",
       "      <td>107989.04</td>\n",
       "      <td>88.42085</td>\n",
       "      <td>5989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol           timestamp       open       high        low      close  \\\n",
       "0  BTCUSDT 2025-09-01 00:00:00  108246.36  108260.00  108210.66  108260.00   \n",
       "1  BTCUSDT 2025-09-01 00:01:00  108260.00  108332.35  108259.99  108332.35   \n",
       "2  BTCUSDT 2025-09-01 00:02:00  108332.35  108332.35  108256.43  108256.44   \n",
       "3  BTCUSDT 2025-09-01 00:03:00  108256.44  108282.43  108229.17  108229.18   \n",
       "4  BTCUSDT 2025-09-01 00:04:00  108229.18  108229.18  108100.00  108100.00   \n",
       "5  BTCUSDT 2025-09-01 00:05:00  108100.00  108110.46  108060.00  108070.04   \n",
       "6  BTCUSDT 2025-09-01 00:06:00  108070.04  108086.17  108015.00  108074.49   \n",
       "7  BTCUSDT 2025-09-01 00:07:00  108074.50  108152.44  108043.23  108152.43   \n",
       "8  BTCUSDT 2025-09-01 00:08:00  108152.43  108152.43  108034.16  108037.77   \n",
       "9  BTCUSDT 2025-09-01 00:09:00  108037.77  108037.78  107983.00  107989.04   \n",
       "\n",
       "     volume  trades  \n",
       "0  15.88924    2717  \n",
       "1  12.94030    1309  \n",
       "2  25.92896    2136  \n",
       "3  18.99223    2344  \n",
       "4  12.05048    3790  \n",
       "5  45.33450    5961  \n",
       "6  26.80768    4855  \n",
       "7  17.08691    3203  \n",
       "8  75.56924    3241  \n",
       "9  88.42085    5989  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('../data/binance_sep_dec28_2025_partial_minute_data.csv')\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DATE RANGE\n",
      "======================================================================\n",
      "Start: 2025-09-01 00:00:00\n",
      "End:   2025-12-05 20:56:00\n",
      "Days:  95 days\n",
      "\n",
      "======================================================================\n",
      "PER SYMBOL BREAKDOWN\n",
      "======================================================================\n",
      "         timestamp                                   volume               \\\n",
      "               min                 max  count           sum         mean   \n",
      "symbol                                                                     \n",
      "BTCUSDT 2025-09-01 2025-12-05 20:56:00  25875  3.731818e+05    14.422485   \n",
      "ETHUSDT 2025-09-01 2025-12-05 20:56:00  25875  9.108531e+06   352.020510   \n",
      "SOLUSDT 2025-09-01 2025-12-05 20:56:00  25875  7.138797e+07  2758.955382   \n",
      "\n",
      "           trades               \n",
      "              sum         mean  \n",
      "symbol                          \n",
      "BTCUSDT  75597655  2921.648502  \n",
      "ETHUSDT  87970659  3399.832232  \n",
      "SOLUSDT  45025709  1740.124019  \n"
     ]
    }
   ],
   "source": [
    "# Date range\n",
    "print(\"=\" * 70)\n",
    "print(\"DATE RANGE\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Start: {df['timestamp'].min()}\")\n",
    "print(f\"End:   {df['timestamp'].max()}\")\n",
    "print(f\"Days:  {(df['timestamp'].max() - df['timestamp'].min()).days} days\")\n",
    "\n",
    "# Per symbol\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PER SYMBOL BREAKDOWN\")\n",
    "print(\"=\" * 70)\n",
    "print(df.groupby('symbol').agg({\n",
    "    'timestamp': ['min', 'max', 'count'],\n",
    "    'volume': ['sum', 'mean'],\n",
    "    'trades': ['sum', 'mean']\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price statistics\n",
    "print(\"=\" * 70)\n",
    "print(\"PRICE STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "for symbol in df['symbol'].unique():\n",
    "    symbol_df = df[df['symbol'] == symbol]\n",
    "    print(f\"\\n{symbol}:\")\n",
    "    print(f\"  Open:   min=${symbol_df['open'].min():,.2f}, max=${symbol_df['open'].max():,.2f}\")\n",
    "    print(f\"  High:   min=${symbol_df['high'].min():,.2f}, max=${symbol_df['high'].max():,.2f}\")\n",
    "    print(f\"  Low:    min=${symbol_df['low'].min():,.2f}, max=${symbol_df['low'].max():,.2f}\")\n",
    "    print(f\"  Close:  min=${symbol_df['close'].min():,.2f}, max=${symbol_df['close'].max():,.2f}\")\n",
    "    print(f\"  Volume: total={symbol_df['volume'].sum():,.2f}, mean={symbol_df['volume'].mean():,.2f}\")\n",
    "    print(f\"  Trades: total={symbol_df['trades'].sum():,.0f}, mean={symbol_df['trades'].mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\n1. Missing Values:\")\n",
    "missing = df.isnull().sum()\n",
    "if missing.sum() == 0:\n",
    "    print(\"   ✓ No missing values\")\n",
    "else:\n",
    "    print(missing[missing > 0])\n",
    "\n",
    "# Check for duplicates\n",
    "print(\"\\n2. Duplicate Timestamps:\")\n",
    "duplicates = df.duplicated(subset=['symbol', 'timestamp']).sum()\n",
    "if duplicates == 0:\n",
    "    print(\"   ✓ No duplicate (symbol, timestamp) pairs\")\n",
    "else:\n",
    "    print(f\"   ✗ Found {duplicates} duplicates\")\n",
    "\n",
    "# Check OHLC validity (high >= open, low <= close, etc.)\n",
    "print(\"\\n3. OHLC Validity:\")\n",
    "invalid_high = (df['high'] < df['open']) | (df['high'] < df['close'])\n",
    "invalid_low = (df['low'] > df['open']) | (df['low'] > df['close'])\n",
    "invalid_range = df['high'] < df['low']\n",
    "\n",
    "total_invalid = invalid_high.sum() + invalid_low.sum() + invalid_range.sum()\n",
    "if total_invalid == 0:\n",
    "    print(\"   ✓ All OHLC relationships valid\")\n",
    "else:\n",
    "    print(f\"   ✗ Invalid high: {invalid_high.sum()}\")\n",
    "    print(f\"   ✗ Invalid low: {invalid_low.sum()}\")\n",
    "    print(f\"   ✗ Invalid range (high < low): {invalid_range.sum()}\")\n",
    "\n",
    "# Check for zero/negative prices\n",
    "print(\"\\n4. Price Validity:\")\n",
    "zero_prices = ((df['open'] <= 0) | (df['high'] <= 0) | (df['low'] <= 0) | (df['close'] <= 0)).sum()\n",
    "if zero_prices == 0:\n",
    "    print(\"   ✓ All prices positive\")\n",
    "else:\n",
    "    print(f\"   ✗ Found {zero_prices} rows with zero/negative prices\")\n",
    "\n",
    "# Check for zero volume\n",
    "print(\"\\n5. Volume/Trades:\")\n",
    "zero_volume = (df['volume'] == 0).sum()\n",
    "zero_trades = (df['trades'] == 0).sum()\n",
    "print(f\"   Zero volume: {zero_volume} rows ({zero_volume/len(df)*100:.2f}%)\")\n",
    "print(f\"   Zero trades: {zero_trades} rows ({zero_trades/len(df)*100:.2f}%)\")\n",
    "if zero_volume == zero_trades:\n",
    "    print(\"   ✓ Zero volume matches zero trades (expected)\")\n",
    "else:\n",
    "    print(\"   ⚠ Mismatch between zero volume and zero trades\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Timestamp Completeness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"TIMESTAMP COMPLETENESS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for symbol in df['symbol'].unique():\n",
    "    symbol_df = df[df['symbol'] == symbol].sort_values('timestamp')\n",
    "    \n",
    "    # Expected number of minutes\n",
    "    start = symbol_df['timestamp'].min()\n",
    "    end = symbol_df['timestamp'].max()\n",
    "    expected_minutes = int((end - start).total_seconds() / 60) + 1\n",
    "    actual_minutes = len(symbol_df)\n",
    "    \n",
    "    print(f\"\\n{symbol}:\")\n",
    "    print(f\"  Expected minutes: {expected_minutes:,}\")\n",
    "    print(f\"  Actual minutes:   {actual_minutes:,}\")\n",
    "    print(f\"  Missing minutes:  {expected_minutes - actual_minutes:,} ({(expected_minutes - actual_minutes)/expected_minutes*100:.2f}%)\")\n",
    "    \n",
    "    # Check for gaps > 1 minute\n",
    "    symbol_df = symbol_df.copy()\n",
    "    symbol_df['time_diff'] = symbol_df['timestamp'].diff()\n",
    "    gaps = symbol_df[symbol_df['time_diff'] > timedelta(minutes=1)]\n",
    "    \n",
    "    if len(gaps) > 0:\n",
    "        print(f\"  Gaps found: {len(gaps)}\")\n",
    "        print(f\"  Largest gap: {gaps['time_diff'].max()}\")\n",
    "        print(f\"\\n  Top 5 largest gaps:\")\n",
    "        top_gaps = gaps.nlargest(5, 'time_diff')[['timestamp', 'time_diff']]\n",
    "        for idx, row in top_gaps.iterrows():\n",
    "            print(f\"    {row['timestamp']}: {row['time_diff']}\")\n",
    "    else:\n",
    "        print(\"  ✓ No gaps > 1 minute\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Price Movement Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate minute-by-minute returns\n",
    "for symbol in df['symbol'].unique():\n",
    "    symbol_df = df[df['symbol'] == symbol].sort_values('timestamp').copy()\n",
    "    symbol_df['returns'] = symbol_df['close'].pct_change() * 100\n",
    "    df.loc[df['symbol'] == symbol, 'returns'] = symbol_df['returns'].values\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"PRICE MOVEMENT STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for symbol in df['symbol'].unique():\n",
    "    symbol_df = df[df['symbol'] == symbol]\n",
    "    returns = symbol_df['returns'].dropna()\n",
    "    \n",
    "    print(f\"\\n{symbol}:\")\n",
    "    print(f\"  Mean return:   {returns.mean():.4f}%\")\n",
    "    print(f\"  Std dev:       {returns.std():.4f}%\")\n",
    "    print(f\"  Min return:    {returns.min():.2f}%\")\n",
    "    print(f\"  Max return:    {returns.max():.2f}%\")\n",
    "    print(f\"  Median:        {returns.median():.4f}%\")\n",
    "    print(f\"  25th pctl:     {returns.quantile(0.25):.4f}%\")\n",
    "    print(f\"  75th pctl:     {returns.quantile(0.75):.4f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"OUTLIER DETECTION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for symbol in df['symbol'].unique():\n",
    "    symbol_df = df[df['symbol'] == symbol]\n",
    "    returns = symbol_df['returns'].dropna()\n",
    "    \n",
    "    # Identify outliers (±3 standard deviations)\n",
    "    mean = returns.mean()\n",
    "    std = returns.std()\n",
    "    outliers = returns[(returns < mean - 3*std) | (returns > mean + 3*std)]\n",
    "    \n",
    "    print(f\"\\n{symbol}:\")\n",
    "    print(f\"  Outliers (±3 std): {len(outliers)} ({len(outliers)/len(returns)*100:.3f}%)\")\n",
    "    \n",
    "    if len(outliers) > 0:\n",
    "        print(f\"  Top 5 positive outliers:\")\n",
    "        top_positive = outliers.nlargest(5)\n",
    "        for val in top_positive:\n",
    "            print(f\"    {val:.2f}%\")\n",
    "        \n",
    "        print(f\"  Top 5 negative outliers:\")\n",
    "        top_negative = outliers.nsmallest(5)\n",
    "        for val in top_negative:\n",
    "            print(f\"    {val:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Price trends\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "for idx, symbol in enumerate(sorted(df['symbol'].unique())):\n",
    "    symbol_df = df[df['symbol'] == symbol].sort_values('timestamp')\n",
    "    \n",
    "    axes[idx].plot(symbol_df['timestamp'], symbol_df['close'], linewidth=0.5, alpha=0.8)\n",
    "    axes[idx].set_title(f'{symbol} - Close Price Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Price (USD)')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add summary stats\n",
    "    start_price = symbol_df['close'].iloc[0]\n",
    "    end_price = symbol_df['close'].iloc[-1]\n",
    "    change_pct = (end_price - start_price) / start_price * 100\n",
    "    \n",
    "    axes[idx].text(0.02, 0.95, \n",
    "                   f'Start: ${start_price:,.2f}\\nEnd: ${end_price:,.2f}\\nChange: {change_pct:+.2f}%',\n",
    "                   transform=axes[idx].transAxes,\n",
    "                   verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5),\n",
    "                   fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return distributions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, symbol in enumerate(sorted(df['symbol'].unique())):\n",
    "    symbol_df = df[df['symbol'] == symbol]\n",
    "    returns = symbol_df['returns'].dropna()\n",
    "    \n",
    "    axes[idx].hist(returns, bins=100, alpha=0.7, edgecolor='black', linewidth=0.5)\n",
    "    axes[idx].set_title(f'{symbol} - Return Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Return (%)')\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].axvline(returns.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {returns.mean():.4f}%')\n",
    "    axes[idx].axvline(returns.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {returns.median():.4f}%')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Volume analysis\n",
    "fig, axes = plt.subplots(3, 1, figsize=(16, 12))\n",
    "\n",
    "for idx, symbol in enumerate(sorted(df['symbol'].unique())):\n",
    "    symbol_df = df[df['symbol'] == symbol].sort_values('timestamp')\n",
    "    \n",
    "    axes[idx].bar(symbol_df['timestamp'], symbol_df['volume'], width=0.0007, alpha=0.6)\n",
    "    axes[idx].set_title(f'{symbol} - Trading Volume Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Date')\n",
    "    axes[idx].set_ylabel('Volume')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add summary\n",
    "    total_vol = symbol_df['volume'].sum()\n",
    "    avg_vol = symbol_df['volume'].mean()\n",
    "    \n",
    "    axes[idx].text(0.02, 0.95,\n",
    "                   f'Total: {total_vol:,.0f}\\nAvg: {avg_vol:,.2f}',\n",
    "                   transform=axes[idx].transAxes,\n",
    "                   verticalalignment='top',\n",
    "                   bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5),\n",
    "                   fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Usability Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"DATA USABILITY ASSESSMENT\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Calculate overall metrics\n",
    "total_rows = len(df)\n",
    "total_symbols = df['symbol'].nunique()\n",
    "date_range_days = (df['timestamp'].max() - df['timestamp'].min()).days\n",
    "\n",
    "# Quality checks\n",
    "has_missing = df.isnull().sum().sum() > 0\n",
    "has_duplicates = df.duplicated(subset=['symbol', 'timestamp']).sum() > 0\n",
    "invalid_ohlc = ((df['high'] < df['open']) | (df['high'] < df['close']) | \n",
    "                (df['low'] > df['open']) | (df['low'] > df['close']) | \n",
    "                (df['high'] < df['low'])).sum() > 0\n",
    "has_invalid_prices = ((df['open'] <= 0) | (df['high'] <= 0) | \n",
    "                      (df['low'] <= 0) | (df['close'] <= 0)).sum() > 0\n",
    "\n",
    "print(f\"\\n✓ Dataset Overview:\")\n",
    "print(f\"  - {total_rows:,} minute candles\")\n",
    "print(f\"  - {total_symbols} symbols (BTCUSDT, ETHUSDT, SOLUSDT)\")\n",
    "print(f\"  - {date_range_days} days of data (Sept 1 - Dec 5, 2025)\")\n",
    "print(f\"  - File size: 5.50 MB\")\n",
    "\n",
    "print(f\"\\n✓ Quality Checks:\")\n",
    "if not has_missing:\n",
    "    print(\"  ✓ No missing values\")\n",
    "else:\n",
    "    print(\"  ✗ Has missing values\")\n",
    "    \n",
    "if not has_duplicates:\n",
    "    print(\"  ✓ No duplicate timestamps\")\n",
    "else:\n",
    "    print(\"  ✗ Has duplicate timestamps\")\n",
    "    \n",
    "if not invalid_ohlc:\n",
    "    print(\"  ✓ All OHLC relationships valid\")\n",
    "else:\n",
    "    print(\"  ✗ Some invalid OHLC values\")\n",
    "    \n",
    "if not has_invalid_prices:\n",
    "    print(\"  ✓ All prices positive\")\n",
    "else:\n",
    "    print(\"  ✗ Some invalid prices\")\n",
    "\n",
    "# Calculate completeness\n",
    "print(f\"\\n✓ Data Completeness:\")\n",
    "for symbol in sorted(df['symbol'].unique()):\n",
    "    symbol_df = df[df['symbol'] == symbol]\n",
    "    expected = int((symbol_df['timestamp'].max() - symbol_df['timestamp'].min()).total_seconds() / 60) + 1\n",
    "    actual = len(symbol_df)\n",
    "    completeness = actual / expected * 100\n",
    "    print(f\"  {symbol}: {completeness:.2f}% complete ({actual:,}/{expected:,} minutes)\")\n",
    "\n",
    "# Overall verdict\n",
    "print(f\"\\n\" + \"=\" * 70)\n",
    "if not (has_missing or has_duplicates or invalid_ohlc or has_invalid_prices):\n",
    "    print(\"✓ DATA IS READY TO USE\")\n",
    "    print(\"  All quality checks passed. No critical issues detected.\")\n",
    "else:\n",
    "    print(\"⚠ DATA HAS ISSUES\")\n",
    "    print(\"  Some quality checks failed. Review issues above.\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Sample Data Export\n",
    "\n",
    "Export a small sample for manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export first 1000 rows for each symbol\n",
    "sample_dfs = []\n",
    "for symbol in sorted(df['symbol'].unique()):\n",
    "    symbol_df = df[df['symbol'] == symbol].sort_values('timestamp').head(1000)\n",
    "    sample_dfs.append(symbol_df)\n",
    "\n",
    "sample = pd.concat(sample_dfs)\n",
    "sample_path = '../data/binance_sample_1000rows_per_symbol.csv'\n",
    "sample.to_csv(sample_path, index=False)\n",
    "\n",
    "print(f\"✓ Exported sample to: {sample_path}\")\n",
    "print(f\"  Rows: {len(sample):,}\")\n",
    "print(f\"  Size: {len(sample) * df.memory_usage(deep=True).sum() / len(df) / 1024:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "DETAILED MISSING RANGES\n",
      "======================================================================\n",
      "\n",
      "--- BTCUSDT ---\n",
      "Found 19 gaps:\n",
      "  Missing: 2025-09-01 21:54:00 to 2025-09-05 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-09-06 21:54:00 to 2025-09-10 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-09-11 21:25:00 to 2025-09-15 23:59:00 | Duration: 4 days 02:36:00\n",
      "  Missing: 2025-09-16 21:54:00 to 2025-09-20 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-09-21 21:12:00 to 2025-09-25 23:59:00 | Duration: 4 days 02:49:00\n",
      "  Missing: 2025-09-26 21:08:00 to 2025-09-30 23:59:00 | Duration: 4 days 02:53:00\n",
      "  Missing: 2025-10-01 21:54:00 to 2025-10-05 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-10-06 21:50:00 to 2025-10-10 23:59:00 | Duration: 4 days 02:11:00\n",
      "  Missing: 2025-10-11 21:20:00 to 2025-10-15 23:59:00 | Duration: 4 days 02:41:00\n",
      "  Missing: 2025-10-16 21:23:00 to 2025-10-20 23:59:00 | Duration: 4 days 02:38:00\n",
      "  Missing: 2025-10-21 21:54:00 to 2025-10-25 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-10-26 21:23:00 to 2025-10-30 23:59:00 | Duration: 4 days 02:38:00\n",
      "  Missing: 2025-10-31 21:23:00 to 2025-11-04 23:59:00 | Duration: 4 days 02:38:00\n",
      "  Missing: 2025-11-05 21:54:00 to 2025-11-09 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-10 21:54:00 to 2025-11-14 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-15 21:02:00 to 2025-11-19 23:59:00 | Duration: 4 days 02:59:00\n",
      "  Missing: 2025-11-20 21:54:00 to 2025-11-24 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-25 21:54:00 to 2025-11-29 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-30 21:06:00 to 2025-12-04 23:59:00 | Duration: 4 days 02:55:00\n",
      "\n",
      "--- ETHUSDT ---\n",
      "Found 19 gaps:\n",
      "  Missing: 2025-09-01 21:54:00 to 2025-09-05 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-09-06 21:54:00 to 2025-09-10 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-09-11 21:25:00 to 2025-09-15 23:59:00 | Duration: 4 days 02:36:00\n",
      "  Missing: 2025-09-16 21:54:00 to 2025-09-20 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-09-21 21:12:00 to 2025-09-25 23:59:00 | Duration: 4 days 02:49:00\n",
      "  Missing: 2025-09-26 21:08:00 to 2025-09-30 23:59:00 | Duration: 4 days 02:53:00\n",
      "  Missing: 2025-10-01 21:54:00 to 2025-10-05 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-10-06 21:50:00 to 2025-10-10 23:59:00 | Duration: 4 days 02:11:00\n",
      "  Missing: 2025-10-11 21:20:00 to 2025-10-15 23:59:00 | Duration: 4 days 02:41:00\n",
      "  Missing: 2025-10-16 21:23:00 to 2025-10-20 23:59:00 | Duration: 4 days 02:38:00\n",
      "  Missing: 2025-10-21 21:54:00 to 2025-10-25 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-10-26 21:23:00 to 2025-10-30 23:59:00 | Duration: 4 days 02:38:00\n",
      "  Missing: 2025-10-31 21:23:00 to 2025-11-04 23:59:00 | Duration: 4 days 02:38:00\n",
      "  Missing: 2025-11-05 21:54:00 to 2025-11-09 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-10 21:54:00 to 2025-11-14 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-15 21:02:00 to 2025-11-19 23:59:00 | Duration: 4 days 02:59:00\n",
      "  Missing: 2025-11-20 21:54:00 to 2025-11-24 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-25 21:54:00 to 2025-11-29 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-30 21:06:00 to 2025-12-04 23:59:00 | Duration: 4 days 02:55:00\n",
      "\n",
      "--- SOLUSDT ---\n",
      "Found 19 gaps:\n",
      "  Missing: 2025-09-01 21:54:00 to 2025-09-05 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-09-06 21:54:00 to 2025-09-10 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-09-11 21:25:00 to 2025-09-15 23:59:00 | Duration: 4 days 02:36:00\n",
      "  Missing: 2025-09-16 21:54:00 to 2025-09-20 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-09-21 21:12:00 to 2025-09-25 23:59:00 | Duration: 4 days 02:49:00\n",
      "  Missing: 2025-09-26 21:08:00 to 2025-09-30 23:59:00 | Duration: 4 days 02:53:00\n",
      "  Missing: 2025-10-01 21:54:00 to 2025-10-05 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-10-06 21:50:00 to 2025-10-10 23:59:00 | Duration: 4 days 02:11:00\n",
      "  Missing: 2025-10-11 21:20:00 to 2025-10-15 23:59:00 | Duration: 4 days 02:41:00\n",
      "  Missing: 2025-10-16 21:23:00 to 2025-10-20 23:59:00 | Duration: 4 days 02:38:00\n",
      "  Missing: 2025-10-21 21:54:00 to 2025-10-25 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-10-26 21:23:00 to 2025-10-30 23:59:00 | Duration: 4 days 02:38:00\n",
      "  Missing: 2025-10-31 21:23:00 to 2025-11-04 23:59:00 | Duration: 4 days 02:38:00\n",
      "  Missing: 2025-11-05 21:54:00 to 2025-11-09 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-10 21:54:00 to 2025-11-14 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-15 21:02:00 to 2025-11-19 23:59:00 | Duration: 4 days 02:59:00\n",
      "  Missing: 2025-11-20 21:54:00 to 2025-11-24 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-25 21:54:00 to 2025-11-29 23:59:00 | Duration: 4 days 02:07:00\n",
      "  Missing: 2025-11-30 21:06:00 to 2025-12-04 23:59:00 | Duration: 4 days 02:55:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"DETAILED MISSING RANGES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for symbol in df['symbol'].unique():\n",
    "    print(f\"\\n--- {symbol} ---\")\n",
    "    symbol_df = df[df['symbol'] == symbol].sort_values('timestamp')\n",
    "    symbol_df['time_diff'] = symbol_df['timestamp'].diff()\n",
    "    \n",
    "    # Find gaps > 1 minute\n",
    "    gaps = symbol_df[symbol_df['time_diff'] > timedelta(minutes=1)]\n",
    "    \n",
    "    if len(gaps) == 0:\n",
    "        print(\"No gaps found.\")\n",
    "    else:\n",
    "        print(f\"Found {len(gaps)} gaps:\")\n",
    "        for idx, row in gaps.iterrows():\n",
    "            gap_end = row['timestamp']\n",
    "            gap_duration = row['time_diff']\n",
    "            # The gap starts 1 minute after the PREVIOUS row\n",
    "            gap_start = gap_end - gap_duration + timedelta(minutes=1)\n",
    "            # The gap ends 1 minute before the CURRENT row\n",
    "            missing_end = gap_end - timedelta(minutes=1)\n",
    "            \n",
    "            print(f\"  Missing: {gap_start} to {missing_end} | Duration: {gap_duration}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
